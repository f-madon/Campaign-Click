# -*- coding: utf-8 -*-
"""TestModels.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZDgasO8hCKNUnMt4h4XIKm0WJu23yn0R

# Preparazione dei dati

## Import dei dati
"""

from google.colab import drive 
import pandas as pd
import re
from glob import glob
import numpy as np

from scipy.stats import pearsonr
import matplotlib.pyplot as plt
import seaborn as sns

drive.mount('/content/gdrive')
#La variabile verrà utilizzata dopo
suspicious_removed = False

!cp -av '/content/gdrive/My Drive/DS Lab - PROGETTO/Dataset aggregati' 'campaignClickDataset'

"""Recupero lisa dei files contenenti i dati"""

part_files = sorted(glob('campaignClickDataset/part*.csv'))

"""## Dataframe

Caricamento dati in un dataframe pandas
"""

df = pd.concat((pd.read_csv(file) for file in part_files), ignore_index=True)

df.dtypes

df.shape

"""Dal comando precedente le colonne totali risultano essere 1416"""

df.columns

"""## Cancellazioni

### Cancellazione delle colonne contenenti solo 0

Verifica colonne contenenti solo 0
"""

zeros_columns = []
for column in df:
    if (df[column] == 0.0).all():
      zeros_columns.append(column)
zeros_columns

"""Rimozione colonne contenenti solo 0 

"""

#removing columns containing only zeros
try:
  #df.drop(list(filter(lambda k: 'feelings' in k, zeros_columns)), axis = 1, inplace = True)
  df.drop(zeros_columns, axis = 1, inplace = True)
except:
  print('Probably the column has already been dropped in a previously execution. Continue')

#removing buy (it contains only zeros, removed by previous step)
#try:
#  df.drop('buy', axis = 1, inplace = True)
#except:
#  print('Probably the column has already been dropped in a previously execution. Continue')
df.shape

"""### Controlli vari

Verifica presenza duplicti iferiti allo user (identificato dalla colonna 'ad_form_id)
"""

df['ad_form_id'].duplicated().any()

"""Verifica presenza di righe con tutti valori a 0, escludendo la prima colonna"""

temp_df = df.drop('ad_form_id', axis=1)
temp_df[(temp_df != 0).all(1)]

#cancellazione temp_df, non più necessaria
del temp_df

"""### Cancellazione Categories2 e Categories3"""

# colonne che devo utilizzare (S perchè utilizzo dopo times1 e times2)
colonne = df.columns.to_numpy()
c2 = re.compile('^categories2+.*', re.IGNORECASE)
c3 = re.compile('^categories3+.*', re.IGNORECASE)
cat2 = []
cat3 = []

for v in colonne:
  if c2.search(v):
    #print(v)
    cat2.append(v)
  if c3.search(v):
    #print(v)
    cat3.append(v)

# elimino colonne 
df.drop(columns=cat2, inplace=True)
df.drop(columns=cat3, inplace=True)

ddd = list(df.columns)
for d in ddd: 
  print(d)

"""### Cancelazione admants e ad_form_id"""

AD = re.compile('^admants+.*', re.IGNORECASE)
admants = []

for v in df.columns:
  if AD.search(v):
    admants.append(v)

admants

df.drop(columns=admants, inplace=True)

# ad_form_id
df[df['ad_form_id'] < 0]

df.drop(columns='ad_form_id', inplace=True)

"""### Rimozione righe con suspicious=1

Estrazione righe con suspicious > 0, eliminazione dal dataframe originale 
Eliminazione colonna 'suspicious'
"""

if suspicious_removed == False:
  suspicious_df = df.loc[df['suspicious'] > 0]
  print('Initial df shape' + str(df.shape))
  df.drop(df[df.suspicious > 0].index, inplace=True)
  df.drop('suspicious', axis = 1, inplace = True)
print('Suspicious shape' + str(suspicious_df.shape))
print('Df shape after removal of suspicious > 0' + str(df.shape))
suspicious_removed = True

"""### Rimozione feelings, impression and time2"""

df.drop(columns='impressions', inplace=True)

colonne = df.columns.to_numpy()
t2 = re.compile('^time2+.*', re.IGNORECASE)
time2 = []

for v in colonne:
  if t2.search(v):
    time2.append(v)

df.drop(columns=time2, inplace=True)

colonne = df.columns.to_numpy()
f = re.compile('^feelings+.*', re.IGNORECASE)
feelings = []

for v in colonne:
  if f.search(v):
    feelings.append(v)

df.drop(columns=feelings, inplace=True)

"""### Aggiunta colonna `click_status`

"""

len(df[df['clicks'] != 0])

df[(df['clicks'] != 0) & (df['clicks'] != 1)]

df['click_status'] = np.where(df['clicks']>0, 'yes', 'no')
df[['clicks', 'click_status']]

len(df[df['click_status'] == 'yes' ])

#df.drop(columns='clicks', inplace=True)

"""## Normalizzazione

### Nornalizzazione colonne Categories
"""

# Colonne categories1
cat1 = re.compile('categories1_+.*', re.IGNORECASE)
cats1 = []
for label in colonne:
  occ = cat1.findall(label)
  if occ:
    cats1.append(occ[0])
  
# Calcolo somma
def somma_cat1(riga):
  sum = 0
  for cat in cats1:
    sum += riga[cat]
  return(round(sum, 1))

df['somma1'] = df.apply(somma_cat1, axis=1)

# Normalizzo le somme a 100
for cat in cats1:
  df[cat] = (df[cat] / df['somma1']) * 100
df['somma1'] = df.apply(somma_cat1, axis=1)

"""#### Rimozione righe con somma 'infinity'"""

df[(df['somma1'] != 100) & (df['somma1'].isnull())][['somma1']]

sum(df['somma1'].isnull())

df['somma1'].shape

indexNames = df[ (df['somma1'].isnull())].index
df.drop(indexNames, inplace=True)
df['somma1'].shape

df.drop(columns=['somma1'], inplace=True)

"""### Normalizzazione di 'Page length'"""

# stampa colonne
L = re.compile('^L+.*', re.IGNORECASE)
lung = []

for v in df.columns:
  if L.search(v):
    print(v)
    lung.append(v)

def somma_lung(riga):
  sum = 0
  for el in lung:
    sum += riga[el]
  return sum

df['somma'] = df.apply(somma_lung, axis=1)
df[['somma']]

from numpy import inf
sum(df['L00_50'] == inf) # infinity solo in L00_50

# NB inf + NaN = NaN

sum(df['somma'] == inf)

sum(df['somma'].isnull())

sum(df['somma'] != 100)

for l in lung:
  df[l] = (df[l] / df['somma']) * 100
df['somma'] = df.apply(somma_lung, axis=1)

df[['L00_50', 'L51_100', 'L101_250', 'L251_500', 'L501_1000', 'L1001_2500', 'L2501_5000', 'L5001_10000', 'L10001_more', 'somma']]

# rimozione coloumn 'somma'
df.drop(columns=['somma'], inplace=True)

"""### Normalizzazione di 'Time'"""

# colonne che devo utilizzare (S perchè utilizzo dopo times1 e times2)
colonne = df.columns.to_numpy()
t1 = re.compile('^time1+.*', re.IGNORECASE)
times1 = []

for v in colonne:
  if t1.search(v):
    print(v)
    times1.append(v)

# calcolo somma dei tempi (S)
df['sommat1'] = (df['time1_workday_morning'] + df['time1_workday_afternoon'] + df['time1_workday_evening'] + df['time1_workday_night'] +
                 df['time1_weekend_morning'] + df['time1_weekend_afternoon'] + df['time1_weekend_evening'] + df['time1_weekend_night'])

# Riscalo i tempi(2) in modo che somma sia 100 (S)
for t1 in times1:
  df[t1] = df[t1]/ df['sommat1']*100

df[times1].head(5)

# passaggi per controllo (arrotondo così non mi dà problemi se chiedo se è pari a 100)

df['sommat1'] = round(df['time1_workday_morning'] + df['time1_workday_afternoon'] + df['time1_workday_evening'] + df['time1_workday_night'] +
                 df['time1_weekend_morning'] + df['time1_weekend_afternoon'] + df['time1_weekend_evening'] + df['time1_weekend_night'], 2)

# controllo: tutte le somme sono a 100, tranne per i NaN

df[(df['sommat1'] != 100)][['sommat1']]

# elimino colonne contenenti la somma dei tempi (S)
df.drop(columns=['sommat1'], inplace=True)

"""## Unione variabili dummy"""

#Aggiunta colonne contenenti solo 0 per salvare i valoridelle variabili dummy
os_type = (np.zeros(df.shape[0], dtype=int))
browser_type = (np.zeros(df.shape[0], dtype=int))

#Aggiunta nuove colonne nel dataframe
df.insert(3, 'os_type', os_type)
df.insert(4, 'browser_type', browser_type)

#Verifica di 'non zero' in colonne os
os = ['android', 'bsd', 'ios', 'linux', 'osx', 'other', 'windows']
for nome in os:
  print(f'non zeros values os_{nome} = ' + str(len(df[df[f'os_{nome}']==1])))

#Rimozione colonna = 'os_ios'
df.drop(columns=['os_ios'], inplace=True)

#Verifica di 'non zero' in colonne os
browser = ['android', 'chrome', 'edge', 'firefox', 'ie', 'opera', 'other', 'safari', 'unknown']
for nome in browser:
  print(f'non zeros values browser_{nome} = ' + str(len(df[df[f'browser_{nome}']==1])))

for i in df.index:
  if df['os_bsd'].loc[i] == 1:
    df.at[i, 'os_type'] = 1
  elif df['os_linux'].loc[i] == 1:
    df.at[i, 'os_type'] = 2
  elif df['os_osx'].loc[i] == 1:
    df.at[i, 'os_type'] = 3
  elif df['os_windows'].loc[i] == 1:
    df.at[i, 'os_type'] = 4
  elif df['os_other'].loc[i] == 1:
    df.at[i, 'os_type'] = 5
  else:
    df.at[i, 'os_type'] = 0

for i in df.index:
  if df['browser_chrome'].loc[i] == 1:
    df.at[i, 'browser_type'] = 1
  elif df['browser_edge'].loc[i] == 1:
    df.at[i, 'browser_type'] = 2
  elif df['browser_firefox'].loc[i] == 1:
    df.at[i, 'browser_type'] = 3
  elif df['browser_ie'].loc[i] == 1:
    df.at[i, 'browser_type'] = 4
  elif df['browser_opera'].loc[i] == 1:
    df.at[i, 'browser_type'] = 5
  elif df['browser_safari'].loc[i] == 1:
    df.at[i, 'browser_type'] = 6
  elif df['browser_other'].loc[i] == 1:
    df.at[i, 'browser_type'] = 7
  elif df['browser_unknown'].loc[i] == 1:
    df.at[i, 'browser_type'] = 8
  else:
    df.at[i, 'browser_type'] = 0

#rimozione colonne ridondanti
df.drop(columns=['os_android', 'os_bsd', 'os_linux', 'os_osx', 'os_other', 'os_windows'], inplace=True)
df.drop(columns=['browser_android', 'browser_chrome', 'browser_edge', 'browser_firefox', 'browser_ie', 'browser_opera', 'browser_other', 'browser_safari', 'browser_unknown'], inplace=True)

"""## Unione colonne 'L'"""

df.shape

##Verifica di 'non zero' in colonne L
lenght = ['L00_50', 'L51_100', 'L101_250', 'L251_500', 'L501_1000', 'L1001_2500', 'L2501_5000', 'L5001_10000', 'L10001_more']
for nome in lenght:
  print(f'non zeros values {nome} = ' + str(len(df[df[f'{nome}']==0])))

L101_500 = df['L101_250'] + df['L251_500']

L501_more = df['L501_1000'] + df['L1001_2500'] + df['L2501_5000'] + df['L5001_10000'] + df['L10001_more']

df.insert(20, 'L101_500', L101_500)
df.insert(21, 'L501_more', L501_more)

zero = df['L00_50']+df['L51_100']+df['L101_500']+df['L501_more']

for riga in zero:
  if riga < 99:
    print(riga)

df.drop(columns=['L101_250', 'L251_500', 'L501_1000', 'L1001_2500', 'L2501_5000', 'L5001_10000', 'L10001_more'], inplace=True)

"""## NaN"""

df.fillna(df.mean(), inplace=True)

# calcolo somma dei tempi (S)
df['sommat1'] = (df['time1_workday_morning'] + df['time1_workday_afternoon'] + df['time1_workday_evening'] + df['time1_workday_night'] +
                 df['time1_weekend_morning'] + df['time1_weekend_afternoon'] + df['time1_weekend_evening'] + df['time1_weekend_night'])

# Riscalo i tempi(2) in modo che somma sia 100 (S)
# for t2 in times2:
#  df[t2] = df[t2]/ df['sommat2']*100

# Riscalo i tempi(1) in modo che somma sia 100 (S)
for t1 in times1:
  df[t1] = df[t1]/ df['sommat1']*100

# elimino colonne contenenti la somma dei tempi (S)
df.drop(columns=['sommat1'], inplace=True)

# passaggi per controllo (arrotondo così non mi dà problemi se chiedo se è pari a 100)

df['sommat1'] = round(df['time1_workday_morning'] + df['time1_workday_afternoon'] + df['time1_workday_evening'] + df['time1_workday_night'] +
                 df['time1_weekend_morning'] + df['time1_weekend_afternoon'] + df['time1_weekend_evening'] + df['time1_weekend_night'], 2)

# controllo: tutte le somme sono a 100

df[(df['sommat1'] != 100)][['sommat1']]

# elimino colonne contenenti la somma dei tempi (S)
df.drop(columns=['sommat1'], inplace=True)

# Controllo colonne nulle (qui per verificare che non ci siano eventuali somme nulle)
df[df.isnull().any(axis=1)]

"""## Colonne con soli 0

Verifica, dopo le modifiche precedenti, se ci sono colonne contenenti solo vlori=0
"""

zeros_columns1 = []
for column in df:
    if (df[column] == 0.0).all():
      zeros_columns1.append(column)
zeros_columns1

"""## Sampling

### Undersampling
"""

# Randomly under sample the majority class
rus = RandomUnderSampler(random_state=42)
train_x_rus, train_y_rus= rus.fit_resample(train_x, train_y)
# Check the number of records after under sampling
print(sorted(Counter(train_y_rus).items()))

"""### Oversampling"""

# Randomly over sample the minority class
ros = RandomOverSampler(random_state=42)
train_x_ros, train_y_ros= ros.fit_resample(train_x, train_y)
# Check the number of records after over sampling
print(sorted(Counter(train_y_ros).items()))

train_x_ros = train_x_ros.append(train_x_ros[43529:])
train_y_ros = train_y_ros.append(train_y_ros[43529:])
print(sorted(Counter(train_y_ros).items()))

"""### SMOTENC"""

train_x.columns

# categorical features
categorical = ['os_type', 'browser_type', 'device_type']
cat_ind = []
i = 0
for cat in categorical:
  cat_ind.append(i)
  i += 1

smotenc = SMOTENC(categorical_features=cat_ind, random_state=42)

x_train_smotenc, y_train_smotenc = smotenc.fit_resample(train_x, train_y)

# Check the number of records after over sampling
print(sorted(Counter(y_train_smotenc).items()))

"""## Cambio tipo colonne"""

train_x_ros = train_x_ros.astype({'os_type': 'object', 'browser_type': 'object', 'device_type': 'object'})

train_x_rus = train_x_rus.astype({'os_type': 'object', 'browser_type': 'object', 'device_type': 'object'})

x_train_smotenc = x_train_smotenc.astype({'os_type': 'object', 'browser_type': 'object', 'device_type': 'object'})

test_x = test_x.astype({'os_type': 'object', 'browser_type': 'object', 'device_type': 'object'})

test_x.dtypes

"""# Modelli

## RandomForest sklearn

Train and test splitting
"""

# Import train_test_split function
from sklearn.model_selection import train_test_split

x=df[df.columns.drop('click_status')]  # Features
y=df['click_status']  # click yes/no

# Split dataset into training set and test set
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, stratify=y) # 70% training and 30% test

print('x: ' + str(x.shape))
print('y: ' + str(y.shape))
print('x_train: ' + str(x_train.shape))
print('y_train: ' + str(y_train.shape))
print('x_test: ' + str(x_test.shape))
print('y_test: ' + str(y_test.shape))

"""Classification   
NB: the default parameters are used for RandomForestClassifier
"""

#Import Random Forest Model
from sklearn.ensemble import RandomForestClassifier

#Create a Gaussian Classifier
clf=RandomForestClassifier(n_estimators=100)

#Train the model using the training sets y_pred=clf.predict(X_test)
clf.fit(x_train,y_train)

y_pred=clf.predict(x_test)

"""Some metrics: visualizing accuracy (only for test)."""

#Import scikit-learn metrics module for accuracy calculation
from sklearn import metrics
# Model Accuracy, how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

y_pred

# View the classification report for test data and predictions
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

"""Feature importance"""

#Feature importance: ci sta che quella più importante sia la 'impressions'
#Ci sono tante features con importance a zero
feature_imp = pd.Series(clf.feature_importances_,index=x.columns).sort_values(ascending=False)
feature_imp

from sklearn.metrics import confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay
cm = confusion_matrix(y_test, y_pred)
cm_display = ConfusionMatrixDisplay(cm).plot()

"""ROC Curve"""

#Non un gran risultato...
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve
from sklearn.metrics import RocCurveDisplay
ax = plt.gca()
rfc_disp = RocCurveDisplay.from_estimator(clf, x_test, y_test, ax=ax, alpha=0.8)
plt.show()

"""Tree visualization"""

# Import tools needed for visualization
from sklearn.tree import export_graphviz
import pydot
# Pull out one tree from the forest
tree = clf.estimators_[5]
# Export the image to a dot file
export_graphviz(tree, out_file = 'tree.dot', feature_names = x.columns, rounded = True, precision = 1)
# Use dot file to create a graph
(graph, ) = pydot.graph_from_dot_file('tree.dot')
# Write graph to a png file
graph.write_png('tree.png')

"""## SVM
* Random undersampling: accuracy 61%, sul test
  * no classificati come no: 61 %
  * no classicati come sì: 39 %
  * sì classificati come no: 38 %
  * sì classificati come sì: 62 %
* Random oversampling (sì e no in numero uguale): accuracy 64%, sul test
  * no classificati come no: 59 %
  * no classicati come sì: 41 %
  * sì classificati come no: 28 %
  * sì classificati come sì: 72 %
* Random oversampling (i sì sono il doppio dei no): accuracy 27%, sul test
  * no classificati come no: 27 %
  * no classicati come sì: 73 %
  * sì classificati come no: 13 %
  * sì classificati come sì: 87 %
* SMOTE-NC: accuracy 64%, sul test
  * no classificati come no: 64 %
  * no classicati come sì: 36 %
  * sì classificati come no: 55 %
  * sì classificati come sì: 45 %

### Random undersampling

#### Training
"""

# Select categorical and numerical features
cat_ix = train_x_rus.select_dtypes(include=['object', 'bool']).columns
num_ix = train_x_rus.select_dtypes(include=['int64', 'float64']).columns

# Define the model
# SVM
model = svm.SVC()

# Random forest
#model = RandomForestClassifier()

# One hot encode categorical, normalize numerical
ct = ColumnTransformer([('c', OneHotEncoder(handle_unknown = 'ignore'), cat_ix),
                        ('n', MinMaxScaler(), num_ix)])

# Define the pipeline
pipeline = Pipeline(steps=[('t', ct), ('m', model)])

# Fit the model
pipeline.fit(train_x_rus, train_y_rus)

# Performance sul train test
y_pred_train = pipeline.predict(train_x_rus)
print(classification_report(train_y_rus, y_pred_train)) # precision, recall e altre misure di performance

# Confusion matrix
ConfusionMatrixDisplay.from_estimator(pipeline, train_x_rus, train_y_rus);

# Percentuali:
a = 100
b = 36
c = 39
d = 97
no = a + b
yes = c + d
CM11 = round(a / no, 2)
CM12 = round(b / no, 2)
CM21 = round(c / yes, 2)
CM22 = round(d / yes, 2)
print(f'% no classificati come no: {CM11}\n% no classicati come sì: {CM12}\n% sì classificati come no: {CM21}\n% sì classificati come sì: {CM22}')

# ROC curve
RocCurveDisplay.from_estimator(pipeline, train_x_rus, train_y_rus);

"""#### Test"""

# Predizione su test set
y_pred = pipeline.predict(test_x)
print(classification_report(test_y, y_pred)) # precision, recall e altre misure di performance

# Confusion matrix
ConfusionMatrixDisplay.from_estimator(pipeline, test_x, test_y);

# Percentuali:
a = 11347
b = 7314
c = 20
d = 33
no = a + b
yes = c + d
CM11 = round(a / no, 2)
CM12 = round(b / no, 2)
CM21 = round(c / yes, 2)
CM22 = round(d / yes, 2)
print(f'% no classificati come no: {CM11}\n% no classicati come sì: {CM12}\n% sì classificati come no: {CM21}\n% sì classificati come sì: {CM22}')

# ROC curve
RocCurveDisplay.from_estimator(pipeline, test_x, test_y);

"""### Random oversampling

#### Training
"""

# Select categorical and numerical features
cat_ix = train_x_ros.select_dtypes(include=['object', 'bool']).columns
num_ix = train_x_ros.select_dtypes(include=['int64', 'float64']).columns

# Define the model
# SVM
model = svm.LinearSVC() # performance migliori rispetto a SVC per dataset con più di 10000 righe

# Random forest
#model = RandomForestClassifier()

# One hot encode categorical, normalize numerical
ct = ColumnTransformer([('c', OneHotEncoder(handle_unknown = 'ignore'), cat_ix),
                        ('n', MinMaxScaler(), num_ix)])

# Define the pipeline
pipeline = Pipeline(steps=[('t', ct), ('m', model)])

# Fit the model
pipeline.fit(train_x_ros, train_y_ros)

# Performance sul train test
y_pred_train = pipeline.predict(train_x_ros)
print(classification_report(train_y_ros, y_pred_train)) # precision, recall e altre misure di performance

# Confusion matrix
ConfusionMatrixDisplay.from_estimator(pipeline, train_x_ros, train_y_ros);

# Percentuali:
a = 11950
b = 31715
c = 3231
d = 83691
no = a + b
yes = c + d
CM11 = round(a / no, 2)
CM12 = round(b / no, 2)
CM21 = round(c / yes, 2)
CM22 = round(d / yes, 2)
print(f'% no classificati come no: {CM11}\n% no classicati come sì: {CM12}\n% sì classificati come no: {CM21}\n% sì classificati come sì: {CM22}')

# ROC curve
RocCurveDisplay.from_estimator(pipeline, train_x_ros, train_y_ros);

"""#### Test"""

# Predizione su test set
y_pred = pipeline.predict(test_x)
print(classification_report(test_y, y_pred)) # precision, recall e altre misure di performance

# Confusion matrix
ConfusionMatrixDisplay.from_estimator(pipeline, test_x, test_y);

# Percentuali:
a = 5077
b = 13584
c = 7
d = 46
no = a + b
yes = c + d
CM11 = round(a / no, 2)
CM12 = round(b / no, 2)
CM21 = round(c / yes, 2)
CM22 = round(d / yes, 2)
print(f'% no classificati come no: {CM11}\n% no classicati come sì: {CM12}\n% sì classificati come no: {CM21}\n% sì classificati come sì: {CM22}')

# ROC curve
RocCurveDisplay.from_estimator(pipeline, test_x, test_y);

"""### SMOTE-NC

#### Training
"""

# Select categorical and numerical features
cat_ix = train_x_ros.select_dtypes(include=['object', 'bool']).columns
num_ix = train_x_ros.select_dtypes(include=['int64', 'float64']).columns

# Define the model
# SVM
model = svm.LinearSVC() # performance migliori rispetto a SVC per dataset con più di 10000 righe

# Random forest
#model = RandomForestClassifier()

# One hot encode categorical, normalize numerical
ct = ColumnTransformer([('c', OneHotEncoder(handle_unknown = 'ignore'), cat_ix),
                        ('n', MinMaxScaler(), num_ix)])

# Define the pipeline
pipeline = Pipeline(steps=[('t', ct), ('m', model)])

# Fit the model
pipeline.fit(x_train_smotenc, y_train_smotenc)

# Performance sul train test
y_pred_train = pipeline.predict(x_train_smotenc)
print(classification_report(y_train_smotenc, y_pred_train)) # precision, recall e altre misure di performance

# Confusion matrix
ConfusionMatrixDisplay.from_estimator(pipeline, x_train_smotenc, y_train_smotenc);

# Percentuali:
a = 28032
b = 15497
c = 9635
d = 33894
no = a + b
yes = c + d
CM11 = round(a / no, 2)
CM12 = round(b / no, 2)
CM21 = round(c / yes, 2)
CM22 = round(d / yes, 2)
print(f'% no classificati come no: {CM11}\n% no classicati come sì: {CM12}\n% sì classificati come no: {CM21}\n% sì classificati come sì: {CM22}')

# ROC curve
RocCurveDisplay.from_estimator(pipeline, x_train_smotenc, y_train_smotenc);

"""#### Test"""

# Predizione su test set
y_pred = pipeline.predict(test_x)
print(classification_report(test_y, y_pred)) # precision, recall e altre misure di performance

# Confusion matrix
ConfusionMatrixDisplay.from_estimator(pipeline, test_x, test_y);

# Percentuali:
a = 11938
b = 6723
c = 29
d = 24
no = a + b
yes = c + d
CM11 = round(a / no, 2)
CM12 = round(b / no, 2)
CM21 = round(c / yes, 2)
CM22 = round(d / yes, 2)
print(f'% no classificati come no: {CM11}\n% no classicati come sì: {CM12}\n% sì classificati come no: {CM21}\n% sì classificati come sì: {CM22}')

# ROC curve
RocCurveDisplay.from_estimator(pipeline, test_x, test_y);

"""## Random Forest
* Random undersampling: overfitta (accuracy da 96% a 60%); 58% sì predetti correttamente sul test set
* Random classifica praticamente tutto come no
* SMOTE-NC: riesce nell'impresa di fare peggio dell'oversampling

### Random undersampling

#### Training
"""

# Select categorical and numerical features
cat_ix = train_x_rus.select_dtypes(include=['object', 'bool']).columns
num_ix = train_x_rus.select_dtypes(include=['int64', 'float64']).columns

# Define the model
# SVM
#model = svm.SVC()

# Random forest
model = RandomForestClassifier()

# One hot encode categorical, normalize numerical
ct = ColumnTransformer([('c', OneHotEncoder(handle_unknown = 'ignore'), cat_ix),
                        ('n', MinMaxScaler(), num_ix)])

# Define the pipeline
pipeline = Pipeline(steps=[('t', ct), ('m', model)])

# Fit the model
pipeline.fit(train_x_rus, train_y_rus)

# Performance sul train test
y_pred_train = pipeline.predict(train_x_rus)
print(classification_report(train_y_rus, y_pred_train)) # precision, recall e altre misure di performance

# Confusion matrix
ConfusionMatrixDisplay.from_estimator(pipeline, train_x_rus, train_y_rus);

# Percentuali:
a = 133
b = 3
c = 7
d = 129
no = a + b
yes = c + d
CM11 = round(a / no, 2)
CM12 = round(b / no, 2)
CM21 = round(c / yes, 2)
CM22 = round(d / yes, 2)
print(f'% no classificati come no: {CM11}\n% no classicati come sì: {CM12}\n% sì classificati come no: {CM21}\n% sì classificati come sì: {CM22}')

# ROC curve
RocCurveDisplay.from_estimator(pipeline, train_x_rus, train_y_rus);

"""#### Test"""

# Predizione su test set
y_pred = pipeline.predict(test_x)
print(classification_report(test_y, y_pred)) # precision, recall e altre misure di performance

# Confusion matrix
ConfusionMatrixDisplay.from_estimator(pipeline, test_x, test_y);

# Percentuali:
a = 11157
b = 7504
c = 22
d = 31
no = a + b
yes = c + d
CM11 = round(a / no, 2)
CM12 = round(b / no, 2)
CM21 = round(c / yes, 2)
CM22 = round(d / yes, 2)
print(f'% no classificati come no: {CM11}\n% no classicati come sì: {CM12}\n% sì classificati come no: {CM21}\n% sì classificati come sì: {CM22}')

# ROC curve
RocCurveDisplay.from_estimator(pipeline, test_x, test_y);

"""### Random oversampling

#### Training
"""

# Select categorical and numerical features
cat_ix = train_x_ros.select_dtypes(include=['object', 'bool']).columns
num_ix = train_x_ros.select_dtypes(include=['int64', 'float64']).columns

# Define the model
# SVM
#model = svm.LinearSVC() # performance migliori rispetto a SVC per dataset con più di 10000 righe

# Random forest
model = RandomForestClassifier()

# One hot encode categorical, normalize numerical
ct = ColumnTransformer([('c', OneHotEncoder(handle_unknown = 'ignore'), cat_ix),
                        ('n', MinMaxScaler(), num_ix)])

# Define the pipeline
pipeline = Pipeline(steps=[('t', ct), ('m', model)])

# Fit the model
pipeline.fit(train_x_ros, train_y_ros)

# Performance sul train test
y_pred_train = pipeline.predict(train_x_ros)
print(classification_report(train_y_ros, y_pred_train)) # precision, recall e altre misure di performance

# Confusion matrix
ConfusionMatrixDisplay.from_estimator(pipeline, train_x_ros, train_y_ros);

# Percentuali:
a = 39101
b = 4564
c = 0
d = 86922
no = a + b
yes = c + d
CM11 = round(a / no, 2)
CM12 = round(b / no, 2)
CM21 = round(c / yes, 2)
CM22 = round(d / yes, 2)
print(f'% no classificati come no: {CM11}\n% no classicati come sì: {CM12}\n% sì classificati come no: {CM21}\n% sì classificati come sì: {CM22}')

# ROC curve
RocCurveDisplay.from_estimator(pipeline, train_x_ros, train_y_ros);

"""#### Test"""

# Predizione su test set
y_pred = pipeline.predict(test_x)
print(classification_report(test_y, y_pred)) # precision, recall e altre misure di performance

# Confusion matrix
ConfusionMatrixDisplay.from_estimator(pipeline, test_x, test_y);

# Percentuali:
a = 16782
b = 1879
c = 46
d = 7
no = a + b
yes = c + d
CM11 = round(a / no, 2)
CM12 = round(b / no, 2)
CM21 = round(c / yes, 2)
CM22 = round(d / yes, 2)
print(f'% no classificati come no: {CM11}\n% no classicati come sì: {CM12}\n% sì classificati come no: {CM21}\n% sì classificati come sì: {CM22}')

# ROC curve
RocCurveDisplay.from_estimator(pipeline, test_x, test_y);

"""### SMOTE-NC

#### Training
"""

# Select categorical and numerical features
cat_ix = train_x_ros.select_dtypes(include=['object', 'bool']).columns
num_ix = train_x_ros.select_dtypes(include=['int64', 'float64']).columns

# Define the model
# SVM
#model = svm.LinearSVC() # performance migliori rispetto a SVC per dataset con più di 10000 righe

# Random forest
model = RandomForestClassifier()

# One hot encode categorical, normalize numerical
ct = ColumnTransformer([('c', OneHotEncoder(handle_unknown = 'ignore'), cat_ix),
                        ('n', MinMaxScaler(), num_ix)])

# Define the pipeline
pipeline = Pipeline(steps=[('t', ct), ('m', model)])

# Fit the model
pipeline.fit(x_train_smotenc, y_train_smotenc)

# Performance sul train test
y_pred_train = pipeline.predict(x_train_smotenc)
print(classification_report(y_train_smotenc, y_pred_train)) # precision, recall e altre misure di performance

# Confusion matrix
ConfusionMatrixDisplay.from_estimator(pipeline, x_train_smotenc, y_train_smotenc);

# Percentuali:
a = 41965
b = 1564
c = 1049
d = 42480
no = a + b
yes = c + d
CM11 = round(a / no, 2)
CM12 = round(b / no, 2)
CM21 = round(c / yes, 2)
CM22 = round(d / yes, 2)
print(f'% no classificati come no: {CM11}\n% no classicati come sì: {CM12}\n% sì classificati come no: {CM21}\n% sì classificati come sì: {CM22}')

# ROC curve
RocCurveDisplay.from_estimator(pipeline, x_train_smotenc, y_train_smotenc);

"""#### Test"""

# Predizione su test set
y_pred = pipeline.predict(test_x)
print(classification_report(test_y, y_pred)) # precision, recall e altre misure di performance

# Confusion matrix
ConfusionMatrixDisplay.from_estimator(pipeline, test_x, test_y);

# Percentuali:
a = 17871
b = 790
c = 49
d = 4
no = a + b
yes = c + d
CM11 = round(a / no, 2)
CM12 = round(b / no, 2)
CM21 = round(c / yes, 2)
CM22 = round(d / yes, 2)
print(f'% no classificati come no: {CM11}\n% no classicati come sì: {CM12}\n% sì classificati come no: {CM21}\n% sì classificati come sì: {CM22}')

# ROC curve
RocCurveDisplay.from_estimator(pipeline, test_x, test_y);