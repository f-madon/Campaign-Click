# -*- coding: utf-8 -*-
"""SVM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18ybHXBp-g1nd4NQ6hN-zQCmOhJSmsKsm

# **SVM migliore**

# Importazione dati
"""

from google.colab import drive 
import pandas as pd
import re
from glob import glob
import numpy as np
from math import exp

from sklearn import svm
from sklearn.ensemble import RandomForestClassifier

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import MinMaxScaler
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer

from sklearn.metrics import classification_report
from sklearn.metrics import RocCurveDisplay
from sklearn.metrics import ConfusionMatrixDisplay

from imblearn.under_sampling import RandomUnderSampler
from collections import Counter
from imblearn.over_sampling import RandomOverSampler
from imblearn.over_sampling import SMOTENC

drive.mount('/content/gdrive')
suspicious_removed = False # Utilizzata dopo

"""Perché il seguente comando funzioni è necessario aggiungere una scorciatoia a DS Lab - PROGETTO al proprio Drive."""

!cp -av '/content/gdrive/My Drive/DS Lab - PROGETTO/Dataset aggregati' 'campaignClickDataset'

"""Lista dei file contenenti i dati"""

part_files = sorted(glob('campaignClickDataset/part*.csv'))

"""# Preprocessing

## Dati in un Dataframe

Carico dati in un dataframe di Pandas
"""

df = pd.concat((pd.read_csv(file) for file in part_files), ignore_index=True)

df.dtypes

df.shape

df.columns

"""## Eliminazione di colonne con soli 0

Controllo colonne con soli 0
"""

zeros_columns = []
for column in df:
    if (df[column] == 0.0).all():
      zeros_columns.append(column)
zeros_columns

# Rimozione
try:
  #df.drop(list(filter(lambda k: 'feelings' in k, zeros_columns)), axis = 1, inplace = True)
  df.drop(zeros_columns, axis = 1, inplace = True)
except:
  print('Probably the column has already been dropped in a previously execution. Continue')

df.shape

"""## Various Checking

Controllo id duplicati
"""

df['ad_form_id'].duplicated().any()

"""Controllo colonne con tutti 0, esclusa prima colonna"""

temp_df = df.drop('ad_form_id', axis=1)
temp_df[(temp_df != 0).all(1)]

# Rimuovo, non serve
del temp_df

"""## Eliminazione suspicious=1"""

# Controllo: righe tolte sono corrette in numero (per come scritto codice meglio non fare modifiche)
len(df[df['suspicious']==1])

# Il controllo if crea problemi nel caso si ri-runni parte del codice senza cancellare memoria


#if suspicious_removed == False:
#  suspicious_df = df.loc[df['suspicious'] > 0]
#  print('Initial df shape' + str(df.shape))
#  df.drop(df[df.suspicious > 0].index, inplace=True)
#  df.drop('suspicious', axis = 1, inplace = True)
#print('Suspicious shape' + str(suspicious_df.shape))
#print('Df shape after removal of suspicious > 0' + str(df.shape))
#suspicious_removed = True

df = df[df['suspicious']==0]

# controllo

df[df['suspicious']==1]

df.drop('suspicious', axis = 1, inplace = True)

"""## Eliminazione admants"""

AD = re.compile('^admants+.*', re.IGNORECASE)
admants = []

for v in df.columns:
  if AD.search(v):
    # print(v)
    admants.append(v)

admants

df.drop(columns=admants, inplace=True)

"""## Eliminazione Categories2 e Categories3"""

# colonne che devo utilizzare
colonne = df.columns.to_numpy()
c2 = re.compile('^categories2+.*', re.IGNORECASE)
c3 = re.compile('^categories3+.*', re.IGNORECASE)
cat2 = []
cat3 = []

for v in colonne:
  if c2.search(v):
    #print(v)
    cat2.append(v)
  if c3.search(v):
    #print(v)
    cat3.append(v)

# elimino colonne 
df.drop(columns=cat2, inplace=True)
df.drop(columns=cat3, inplace=True)

# Controllo

ddd = list(df.columns)
for d in ddd: 
  print(d)

"""## Eliminazione impressions = 0"""

df = df[df['impressions'] != 0]

"""## Aggiunta `click_status` e eliminazione `clicks`"""

# nuemero totale di persone che cliccano
len(df[df['clicks'] != 0])

#alcuni click maggiori di 1
df[(df['clicks'] != 0) & (df['clicks'] != 1)].head()

# aggiungo nuova colonna che indica se click è avvenuto o meno
df['click_status'] = np.where(df['clicks']>0, 'yes', 'no')
df[['clicks', 'click_status']].head()

#controllo che yes coincidano con click != 0
len(df[df['click_status'] == 'yes' ])

#elimino colonna click
df.drop(columns='clicks', inplace=True)

"""## Normalizzazione

### Normalizazzione categories
"""

# Colonne categories1
cat1 = re.compile('categories1_+.*', re.IGNORECASE)
cats1 = []
for label in colonne:
  occ = cat1.findall(label)
  if occ:
    cats1.append(occ[0])
  
# Calcolo somma
def somma_cat1(riga):
  sum = 0
  for cat in cats1:
    sum += riga[cat]
  return(round(sum, 1))

df['somma1'] = df.apply(somma_cat1, axis=1)

# controllo quanti nan ci sono nelle somme: non ci sono nan

df[df['somma1'].isnull()][['ad_form_id', 'click_status', 'somma1']]

# controllo se ci sono nan nelle categorie singole: non ci sono

for v in cats1:
  nn = len(df[df[v].isnull()])
  if (nn != 0):
    print(v, nn)

# controllo gli infiniti: sono 15843 righe
df[df['somma1'] == np.inf][['ad_form_id', 'click_status', 'somma1']]

# controllo gli zero: sono 4170 righe
df[df['somma1'] == 0][['ad_form_id', 'click_status', 'somma1']]

# conto quante somme a zero e a infinito ci sono, devono corrispondere poi con le somme a nan dopo la normalizzazione e il ricalcolo della somma:
# corrispondono (20011)

len(df[(df['somma1'] == 0)  | (df['somma1'] == np.inf)])

# quanti click_status yes vengono persi: 59. Ok.

len(df[((df['somma1'] == 0)  | (df['somma1'] == np.inf)) & (df['click_status'] == 'yes')][['ad_form_id', 'click_status', 'somma1']])

# Normalizzo le somme a 100
for cat in cats1:
  df[cat] = (df[cat] / df['somma1']) * 100

# ricacolo somma
df['somma1'] = df.apply(somma_cat1, axis=1)
# nota: verrà eliminata nel paragrafo sotto

# Controllo
# Tolgo i valori nulli perché il ciclo for trasforma le somme infinite in NaN
df[((df['somma1'] < 99.5) | (df['somma1'] > 100.5) )& (df['somma1'].notnull())][['ad_form_id','somma1']]

"""
### Eliminazione somme infinite in categories"""

# numero di righe per cui somma è NaN
sum(df['somma1'].isnull())

# numero di righe totali
len(df['somma1'])

# elimino righe per cui somma a NaN

indexNames = df[ (df['somma1'].isnull())].index
df.drop(indexNames, inplace=True)
df['somma1'].shape

# Elimino colonna somma1, non utile

df.drop(columns=['somma1'], inplace=True)

"""### Normalizzazione lunghezza pagine"""

L = re.compile('^L+.*', re.IGNORECASE)
lung = []

for v in df.columns:
  if L.search(v):
    print(v)
    lung.append(v)

def somma_lung(riga):
  sum = 0
  for el in lung:
    sum += riga[el]
  return sum

df['somma'] = df.apply(somma_lung, axis=1)
df[['somma']]

# no valori infiniti

from numpy import inf
sum(df['somma'] == inf)

# NB inf + NaN = NaN

# no valori nulli

sum(df['somma'].isnull())

# normalizzo
for l in lung:
  df[l] = (df[l] / df['somma']) * 100
df['somma'] = df.apply(somma_lung, axis=1)

# controllo
df[['L00_50', 'L51_100', 'L101_250', 'L251_500', 'L501_1000', 'L1001_2500', 'L2501_5000', 'L5001_10000', 'L10001_more', 'somma']]

#controllo: tutte le somme sono a 100

df[ (df['somma']> 100.1)| (df['somma']< 99.8)]

# delete coloumn 'somma'
df.drop(columns=['somma'], inplace=True)

"""### Normalizzazione tempi"""

# colonne che devo utilizzare (S perchè utilizzo dopo times1 e times2)
colonne = df.columns.to_numpy()
t = re.compile('^time+.*', re.IGNORECASE)
t1 = re.compile('^time1+.*', re.IGNORECASE)
times1 = []
times2 = []

for v in colonne:
  if t.search(v):
    print(v)
    if t1.search(v):
      times1.append(v)
    else:
      times2.append(v)

# calcolo somma dei tempi (S)
df['sommat1'] = (df['time1_workday_morning'] + df['time1_workday_afternoon'] + df['time1_workday_evening'] + df['time1_workday_night'] +
                 df['time1_weekend_morning'] + df['time1_weekend_afternoon'] + df['time1_weekend_evening'] + df['time1_weekend_night'])

df['sommat2'] = (df['time2_morning_early'] + df['time2_morning'] + df['time2_launch'] + df['time2_afternoon'] + df['time2_evening'] +
                 df['time2_night'])# + df['time2_sleep']) #time2_sleep previously removed because containing only zeros

# Riscalo i tempi(1) in modo che somma sia 100 (S)
for t2 in times2:
  df[t2] = df[t2]/ df['sommat2']*100

df[times2].head(5)

# Riscalo i tempi(2) in modo che somma sia 100 (S)
for t1 in times1:
  df[t1] = df[t1]/ df['sommat1']*100

df[times1].head(5)

# elimino colonne contenenti la somma dei tempi (S)
df.drop(columns=['sommat1', 'sommat2'], inplace=True)

# passaggi per controllo (arrotondo così non mi dà problemi se chiedo se è pari a 100)

df['sommat1'] = round(df['time1_workday_morning'] + df['time1_workday_afternoon'] + df['time1_workday_evening'] + df['time1_workday_night'] +
                 df['time1_weekend_morning'] + df['time1_weekend_afternoon'] + df['time1_weekend_evening'] + df['time1_weekend_night'], 2)

df['sommat2'] = round(df['time2_morning_early'] + df['time2_morning'] + df['time2_launch'] + df['time2_afternoon'] + df['time2_evening'] +
                 df['time2_night'], 2)

# controllo: tutte le somme sono a 100, tranne per i NaN

df[(df['sommat1'] != 100) | (df['sommat2'] > 100) | (df['sommat2'] < 100)][['sommat1', 'sommat2']]

# ci sono molte colonne con valori NaN

df[df['sommat2'].isnull()][['sommat1','sommat2']]

# elimino colonne contenenti la somma dei tempi (S)
df.drop(columns=['sommat1', 'sommat2'], inplace=True)

"""## Unione L"""

#Control of non zeros values in L
lenght = ['L00_50', 'L51_100', 'L101_250', 'L251_500', 'L501_1000', 'L1001_2500', 'L2501_5000', 'L5001_10000', 'L10001_more']
for nome in lenght:
  print(f'non zeros values {nome} = ' + str(len(df[df[f'{nome}']==0])))

L101_500 = df['L101_250'] + df['L251_500']
L501_more = df['L501_1000'] + df['L1001_2500'] + df['L2501_5000'] + df['L5001_10000'] + df['L10001_more']

df.insert(31, 'L101_500', L101_500)
df.insert(32, 'L501_more', L501_more)

# controllo: tutte le colonne sommano ancora a 100
zero = round(df['L00_50']+df['L51_100']+df['L101_500']+df['L501_more'],2)

for riga in zero:
  if (riga != 100):
    print(riga)

# elimino colonne non utili

df.drop(columns=['L101_250', 'L251_500', 'L501_1000', 'L1001_2500', 'L2501_5000', 'L5001_10000', 'L10001_more'], inplace=True)

"""## Rimozione times2"""

df.drop(times2, axis=1, inplace=True)

"""## Rimozione impressions"""

df.drop('impressions', axis=1, inplace=True)

"""## Rimozione feelings"""

# colonne che devo utilizzare (S perchè utilizzo dopo times1 e times2)
colonne = df.columns.to_numpy()
t = re.compile('^feelings+.*', re.IGNORECASE)
t1 = re.compile('^feelings+.*', re.IGNORECASE)
feelings = []

for v in colonne:
  if t.search(v):
    print(v)
    if t1.search(v):
      feelings.append(v)

df.drop(feelings, axis=1, inplace=True)

"""## Rimozione id"""

df.drop('ad_form_id', axis=1, inplace=True)

"""## Unione variabili binarie"""

# Creazione colonne con soli 0, da riempire
os_type = (np.zeros(df.shape[0], dtype=int))
browser_type = (np.zeros(df.shape[0], dtype=int))

df.insert(3, 'os_type', os_type)
df.insert(4, 'browser_type', browser_type)

# Controllo
os = ['android', 'bsd', 'ios', 'linux', 'osx', 'other', 'windows']
for nome in os:
  print(f'non zeros values os_{nome} = ' + str(len(df[df[f'os_{nome}']==1])))

#Eliminazione di 'os_ios'
df.drop(columns=['os_ios'], inplace=True)

#Controllo
browser = ['android', 'chrome', 'edge', 'firefox', 'ie', 'opera', 'other', 'safari', 'unknown']
for nome in browser:
  print(f'non zeros values browser_{nome} = ' + str(len(df[df[f'browser_{nome}']==1])))

for i in df.index:
  if df['os_bsd'].loc[i] == 1:
    df.at[i, 'os_type'] = 1
  elif df['os_linux'].loc[i] == 1:
    df.at[i, 'os_type'] = 2
  elif df['os_osx'].loc[i] == 1:
    df.at[i, 'os_type'] = 3
  elif df['os_windows'].loc[i] == 1:
    df.at[i, 'os_type'] = 4
  elif df['os_other'].loc[i] == 1:
    df.at[i, 'os_type'] = 5
  else:
    df.at[i, 'os_type'] = 0

for i in df.index:
  if df['browser_chrome'].loc[i] == 1:
    df.at[i, 'browser_type'] = 1
  elif df['browser_edge'].loc[i] == 1:
    df.at[i, 'browser_type'] = 2
  elif df['browser_firefox'].loc[i] == 1:
    df.at[i, 'browser_type'] = 3
  elif df['browser_ie'].loc[i] == 1:
    df.at[i, 'browser_type'] = 4
  elif df['browser_opera'].loc[i] == 1:
    df.at[i, 'browser_type'] = 5
  elif df['browser_safari'].loc[i] == 1:
    df.at[i, 'browser_type'] = 6
  elif df['browser_other'].loc[i] == 1:
    df.at[i, 'browser_type'] = 7
  elif df['browser_unknown'].loc[i] == 1:
    df.at[i, 'browser_type'] = 8
  else:
    df.at[i, 'browser_type'] = 0

#Eliminazione colonne ripetitive
df.drop(columns=['os_android', 'os_bsd', 'os_linux', 'os_osx', 'os_other', 'os_windows'], inplace=True)
df.drop(columns=['browser_android', 'browser_chrome', 'browser_edge', 'browser_firefox', 'browser_ie', 'browser_opera', 'browser_other', 'browser_safari', 'browser_unknown'], inplace=True)

"""## Divisione train test"""

feature_names = df.columns.drop('click_status')

(train_x, test_x,
 train_y, test_y) = train_test_split(df[feature_names], 
                                     df['click_status'],
                                     test_size=0.3, random_state=42)

"""## Campionamento

### Oversampling
"""

ros = RandomOverSampler(random_state=42)
train_x_ros, train_y_ros= ros.fit_resample(train_x, train_y)

print(sorted(Counter(train_y_ros).items()))

"""## Cambio tipo colonne"""

train_x_ros = train_x_ros.astype({'os_type': 'object', 'browser_type': 'object', 'device_type': 'object'})

test_x = test_x.astype({'os_type': 'object', 'browser_type': 'object', 'device_type': 'object'})

test_x.dtypes

"""# SVM
* Random oversampling (sì e no in numero uguale): accuracy 64%, sul test
  * no classificati come no: 59 %
  * no classicati come sì: 41 %
  * sì classificati come no: 28 %
  * sì classificati come sì: 72 %

### Training
"""

# Seleziono variabili categoriche e numeriche
cat_ix = train_x_ros.select_dtypes(include=['object', 'bool']).columns
num_ix = train_x_ros.select_dtypes(include=['int64', 'float64']).columns

# SVM
model = svm.LinearSVC()

# Encoding e normalizzazione
ct = ColumnTransformer([('c', OneHotEncoder(handle_unknown = 'ignore'), cat_ix),
                        ('n', MinMaxScaler(), num_ix)])

# Definisco pipeline
pipeline = Pipeline(steps=[('t', ct), ('m', model)])

# Addestramento
pipeline.fit(train_x_ros, train_y_ros)

# Performance sul train test
y_pred_train = pipeline.predict(train_x_ros)
print(classification_report(train_y_ros, y_pred_train)) # precision, recall e altre misure di performance

# Matrice di confusione
ConfusionMatrixDisplay.from_estimator(pipeline, train_x_ros, train_y_ros);

# Percentuali:
a = 25745
b = 17784
c = 12972
d = 3e4
no = a + b
yes = c + d
CM11 = round(a / no, 2)
CM12 = round(b / no, 2)
CM21 = round(c / yes, 2)
CM22 = round(d / yes, 2)
print(f'% no classificati come no: {CM11}\n% no classicati come sì: {CM12}\n% sì classificati come no: {CM21}\n% sì classificati come sì: {CM22}')

# Curva ROC
RocCurveDisplay.from_estimator(pipeline, train_x_ros, train_y_ros);

"""### Test"""

# Predizione su test set
y_pred = pipeline.predict(test_x)
print(classification_report(test_y, y_pred)) # precision, recall e altre misure di performance

# Matrice di confusione
ConfusionMatrixDisplay.from_estimator(pipeline, test_x, test_y, colorbar=False, cmap='gist_yarg');

# Matrice di confusione con percentuali
ConfusionMatrixDisplay.from_estimator(pipeline, test_x, test_y, colorbar=False, cmap='binary', normalize='true');

# Percentuali:
a = 10930
b = 7731
c = 15
d = 38
no = a + b
yes = c + d
CM11 = round(a / no, 2)
CM12 = round(b / no, 2)
CM21 = round(c / yes, 2)
CM22 = round(d / yes, 2)
print(f'% no classificati come no: {CM11}\n% no classicati come sì: {CM12}\n% sì classificati come no: {CM21}\n% sì classificati come sì: {CM22}')

# Curva ROC
RocCurveDisplay.from_estimator(pipeline, test_x, test_y);

"""# Valutazione

Da guida di `sklearn` su decision function di `linearSVC`:

*Predict confidence scores for samples.*

*The confidence score for a sample is proportional to the signed distance of that sample to the hyperplane.*

*Parameters*
  * *X{array-like, sparse matrix} of shape (`n_samples`, `n_features`)*
    * *The data matrix for which we want to get the confidence scores.*

*Returns*
  * *scores: ndarray of shape (`n_samples`,) or (`n_samples`, `n_classes`)*
    * *Confidence scores per (`n_samples`, `n_classes`) combination. In the binary case, confidence score for `self.classes_[1]` where >0 means this class would be predicted.*
"""

# Confidenza dei sì
probs = list(pipeline.decision_function(test_x))

probs[:10]

# La prima entrata di ogni entrata di probs è associata al no, la seconda al sì, come mostrato qui sotto
y_pred[:10]

# Costruisco ora dataframe con id, la classe vera e la probabilità associata al sì
yes_df = pd.DataFrame()

yes_df['id'] = range(len(probs))
yes_df['Class'] = list(test_y)
yes_df['Predicted'] = list(y_pred)
yes_df['Confidence of yes'] = probs

yes_df

"""Si possono mappare tra 0 e 1 usando:

$\frac{1}{1+e^{-c}},$

con c livello di confidenza, ma i valori non seguono nessuna distribuzione di probabilità.
"""

def ctp(riga):
  return 1 / (1 + exp(-riga['Confidence of yes']))
yes_df['Confidence of yes'] = yes_df.apply(ctp, axis=1)

yes_df[yes_df['Class'] == 'yes'].sort_values('Confidence of yes', ascending=False)

yes_df.groupby('Class').size()

Nno = 18661
Nyes = 53

"""## Mediana"""

# Individuo la mediana e divido in gruppi
group1 = yes_df[yes_df['Confidence of yes'] >= yes_df['Confidence of yes'].median()]
group2 = yes_df[yes_df['Confidence of yes'] < yes_df['Confidence of yes'].median()]

yes_df['Confidence of yes'].median()

# Guardo la probabilità del primo gruppo
print(f"Frazione di sì reali nel primo gruppo: {list(group1[group1['Class'] == 'yes'].count())[2]}/{len(group1)}={round(list(group1[group1['Class'] == 'yes'].count() / len(group1))[2], 3)}")
print(f"Frazione di sì reali nel primo gruppo su tutti i sì: {list(group1[group1['Class'] == 'yes'].count())[2]}/{Nyes}")
print(f"Frazione di no reali nel primo gruppo su tutti i no: {list(group1[group1['Class'] == 'no'].count())[2]}/{Nno}")

# Guardo la probabilità del secondo gruppo
print(f"Frazione di sì reali nel secondo gruppo: {list(group2[group2['Class'] == 'yes'].count())[2]}/{len(group2)}={round(list(group2[group2['Class'] == 'yes'].count() / len(group2))[2], 3)}")
print(f"Frazione di sì reali nel secondo gruppo su tutti i sì: {list(group2[group2['Class'] == 'yes'].count())[2]}/{Nyes}")
print(f"Frazione di no reali nel secondo gruppo su tutti i no: {list(group2[group2['Class'] == 'no'].count())[2]}/{Nno}")

"""## Quartili"""

quart1 = yes_df[(yes_df['Confidence of yes'] <= yes_df['Confidence of yes'].quantile(q=1.0)) &
                (yes_df['Confidence of yes'] >= yes_df['Confidence of yes'].quantile(q=0.75))]
quart2 = yes_df[(yes_df['Confidence of yes'] < yes_df['Confidence of yes'].quantile(q=0.75)) &
                (yes_df['Confidence of yes'] >= yes_df['Confidence of yes'].quantile(q=0.5))]
quart3 = yes_df[(yes_df['Confidence of yes'] < yes_df['Confidence of yes'].quantile(q=0.5)) &
                (yes_df['Confidence of yes'] >= yes_df['Confidence of yes'].quantile(q=0.25))]
quart4 = yes_df[(yes_df['Confidence of yes'] < yes_df['Confidence of yes'].quantile(q=0.25)) &
                (yes_df['Confidence of yes'] >= yes_df['Confidence of yes'].quantile(q=0))]

# Quartili
print(f"q_0.75 = {yes_df['Confidence of yes'].quantile(q=0.75)}")
print(f"mediana = {yes_df['Confidence of yes'].quantile(q=0.5)}")
print(f"q_0.25 = {yes_df['Confidence of yes'].quantile(q=0.25)}")
print(f"q_0 = {yes_df['Confidence of yes'].quantile(q=0)}")

# Guardo la probabilità del primo gruppo
print(f"Frazione di sì reali nel primo gruppo: {list(quart1[quart1['Class'] == 'yes'].count())[2]}/{len(quart1)}={round(list(quart1[quart1['Class'] == 'yes'].count() / len(quart1))[2], 3)}")
print(f"Frazione di sì reali nel primo gruppo su tutti i sì: {list(quart1[quart1['Class'] == 'yes'].count())[2]}/{Nyes}")
print(f"Frazione di no reali nel primo gruppo su tutti i no: {list(quart1[quart1['Class'] == 'no'].count())[2]}/{Nno}")

# Guardo la probabilità del secondo gruppo
print(f"Frazione di sì reali nel secondo gruppo: {list(quart2[quart2['Class'] == 'yes'].count())[2]}/{len(quart2)}={round(list(quart2[quart2['Class'] == 'yes'].count() / len(quart2))[2], 3)}")
print(f"Frazione di sì reali nel secondo gruppo su tutti i sì: {list(quart2[quart2['Class'] == 'yes'].count())[2]}/{Nyes}")
print(f"Frazione di no reali nel secondo gruppo su tutti i no: {list(quart2[quart2['Class'] == 'no'].count())[2]}/{Nno}")

# Guardo la probabilità del terzo gruppo
print(f"Frazione di sì reali nel terzo gruppo: {list(quart3[quart3['Class'] == 'yes'].count())[2]}/{len(quart3)}={round(list(quart3[quart3['Class'] == 'yes'].count() / len(quart3))[2], 3)}")
print(f"Frazione di sì reali nel terzo gruppo su tutti i sì: {list(quart3[quart3['Class'] == 'yes'].count())[2]}/{Nyes}")
print(f"Frazione di no reali nel terzo gruppo su tutti i no: {list(quart3[quart3['Class'] == 'no'].count())[2]}/{Nno}")

# Guardo la probabilità del quarto gruppo
print(f"Frazione di sì reali nel quarto gruppo: {list(quart4[quart4['Class'] == 'yes'].count())[2]}/{len(quart4)}={round(list(quart4[quart4['Class'] == 'yes'].count() / len(quart4))[2], 3)}")
print(f"Frazione di sì reali nel quarto gruppo su tutti i sì: {list(quart4[quart4['Class'] == 'yes'].count())[2]}/{Nyes}")
print(f"Frazione di no reali nel quarto gruppo su tutti i no: {list(quart4[quart4['Class'] == 'no'].count())[2]}/{Nno}")

"""## Ottili"""

ott1 = yes_df[(yes_df['Confidence of yes'] <= yes_df['Confidence of yes'].quantile(q=1.0)) &
              (yes_df['Confidence of yes'] >= yes_df['Confidence of yes'].quantile(q=0.875))]
ott2 = yes_df[(yes_df['Confidence of yes'] < yes_df['Confidence of yes'].quantile(q=0.875)) &
              (yes_df['Confidence of yes'] >= yes_df['Confidence of yes'].quantile(q=0.75))]
ott3 = yes_df[(yes_df['Confidence of yes'] < yes_df['Confidence of yes'].quantile(q=0.75)) &
              (yes_df['Confidence of yes'] >= yes_df['Confidence of yes'].quantile(q=0.625))]
ott4 = yes_df[(yes_df['Confidence of yes'] < yes_df['Confidence of yes'].quantile(q=0.625)) &
              (yes_df['Confidence of yes'] >= yes_df['Confidence of yes'].quantile(q=0.5))]
ott5 = yes_df[(yes_df['Confidence of yes'] < yes_df['Confidence of yes'].quantile(q=0.5)) &
              (yes_df['Confidence of yes'] >= yes_df['Confidence of yes'].quantile(q=0.375))]
ott6 = yes_df[(yes_df['Confidence of yes'] < yes_df['Confidence of yes'].quantile(q=0.375)) &
              (yes_df['Confidence of yes'] >= yes_df['Confidence of yes'].quantile(q=0.25))]
ott7 = yes_df[(yes_df['Confidence of yes'] < yes_df['Confidence of yes'].quantile(q=0.25)) &
              (yes_df['Confidence of yes'] >= yes_df['Confidence of yes'].quantile(q=0.125))]
ott8 = yes_df[(yes_df['Confidence of yes'] < yes_df['Confidence of yes'].quantile(q=0.125)) &
              (yes_df['Confidence of yes'] >= yes_df['Confidence of yes'].quantile(q=0))]

# Ottili
print(f"q_0.875 = {yes_df['Confidence of yes'].quantile(q=0.875)}")
print(f"q_0.625 = {yes_df['Confidence of yes'].quantile(q=0.625)}")
print(f"q_0.375 = {yes_df['Confidence of yes'].quantile(q=0.375)}")
print(f"q_0.125 = {yes_df['Confidence of yes'].quantile(q=0.125)}")

# Guardo la probabilità del primo gruppo
print(f"Frazione di sì reali nel primo gruppo: {list(ott1[ott1['Class'] == 'yes'].count())[2]}/{len(ott1)}={round(list(ott1[ott1['Class'] == 'yes'].count() / len(ott1))[2], 3)}")
print(f"Frazione di sì reali nel primo gruppo su tutti i sì: {list(ott1[ott1['Class'] == 'yes'].count())[2]}/{Nyes}")
print(f"Frazione di no reali nel primo gruppo su tutti i no: {list(ott1[ott1['Class'] == 'no'].count())[2]}/{Nno}")

# Guardo la probabilità del secondo gruppo
print(f"Frazione di sì reali nel secondo gruppo: {list(ott2[ott2['Class'] == 'yes'].count())[2]}/{len(ott2)}={round(list(ott2[ott2['Class'] == 'yes'].count() / len(ott2))[2], 3)}")
print(f"Frazione di sì reali nel secondo gruppo su tutti i sì: {list(ott2[ott2['Class'] == 'yes'].count())[2]}/{Nyes}")
print(f"Frazione di no reali nel secondo gruppo su tutti i no: {list(ott2[ott2['Class'] == 'no'].count())[2]}/{Nno}")

# Guardo la probabilità del terzo ottile
print(f"Frazione di sì reali nel terzo gruppo: {list(ott3[ott3['Class'] == 'yes'].count())[2]}/{len(ott3)}={round(list(ott3[ott3['Class'] == 'yes'].count() / len(ott3))[2], 3)}")
print(f"Frazione di sì reali nel terzo gruppo su tutti i sì: {list(ott3[ott3['Class'] == 'yes'].count())[2]}/{Nyes}")
print(f"Frazione di no reali nel terzo gruppo su tutti i no: {list(ott3[ott3['Class'] == 'no'].count())[2]}/{Nno}")

# Guardo la probabilità del quarto gruppo
print(f"Frazione di sì reali nel quarto gruppo: {list(ott4[ott4['Class'] == 'yes'].count())[2]}/{len(ott4)}={round(list(ott4[ott4['Class'] == 'yes'].count() / len(ott4))[2], 3)}")
print(f"Frazione di sì reali nel quarto gruppo su tutti i sì: {list(ott4[ott4['Class'] == 'yes'].count())[2]}/{Nyes}")
print(f"Frazione di no reali nel quarto gruppo su tutti i no: {list(ott4[ott4['Class'] == 'no'].count())[2]}/{Nno}")

# Guardo la probabilità del quinto gruppo
print(f"Frazione di sì reali nel quinto gruppo: {list(ott5[ott5['Class'] == 'yes'].count())[2]}/{len(ott5)}={round(list(ott5[ott5['Class'] == 'yes'].count() / len(ott5))[2], 3)}")
print(f"Frazione di sì reali nel quinto gruppo su tutti i sì: {list(ott5[ott5['Class'] == 'yes'].count())[2]}/{Nyes}")
print(f"Frazione di no reali nel quinto gruppo su tutti i no: {list(ott5[ott5['Class'] == 'no'].count())[2]}/{Nno}")

# Guardo la probabilità del sesto gruppo
print(f"Frazione di sì reali nel sesto gruppo: {list(ott6[ott6['Class'] == 'yes'].count())[2]}/{len(ott6)}={round(list(ott6[ott6['Class'] == 'yes'].count() / len(ott6))[2], 3)}")
print(f"Frazione di sì reali nel sesto gruppo su tutti i sì: {list(ott6[ott6['Class'] == 'yes'].count())[2]}/{Nyes}")
print(f"Frazione di no reali nel sesto gruppo su tutti i no: {list(ott6[ott6['Class'] == 'no'].count())[2]}/{Nno}")

# Guardo la probabilità del settimo gruppo
print(f"Frazione di sì reali nel settimo gruppo: {list(ott7[ott7['Class'] == 'yes'].count())[2]}/{len(ott7)}={round(list(ott7[ott7['Class'] == 'yes'].count() / len(ott7))[2], 3)}")
print(f"Frazione di sì reali nel settimo gruppo su tutti i sì: {list(ott7[ott7['Class'] == 'yes'].count())[2]}/{Nyes}")
print(f"Frazione di no reali nel settimo gruppo su tutti i no: {list(ott7[ott7['Class'] == 'no'].count())[2]}/{Nno}")

# Guardo la probabilità dell'ottavo gruppo
print(f"Frazione di sì reali nell'ottavo gruppo: {list(ott8[ott8['Class'] == 'yes'].count())[2]}/{len(ott8)}={round(list(ott8[ott8['Class'] == 'yes'].count() / len(ott8))[2], 3)}")
print(f"Frazione di sì reali nell'ottavo gruppo su tutti i sì: {list(ott8[ott8['Class'] == 'yes'].count())[2]}/{Nyes}")
print(f"Frazione di no reali nell'ottavo gruppo su tutti i no: {list(ott8[ott8['Class'] == 'no'].count())[2]}/{Nno}")